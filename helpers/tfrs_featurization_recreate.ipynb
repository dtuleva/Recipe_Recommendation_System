{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtuleva/Recipe_Recommendation_System/blob/main/tfrs_featurization_recreate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders"
      ],
      "metadata": {
        "id": "hXdH45vFtqWh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ZCJz8EsdtwPz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recreate TFRS tutorial: Using side features: feature preprocessing"
      ],
      "metadata": {
        "id": "dtVtK_vVtatj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFJUp0Vdu-TG"
      },
      "source": [
        "One of the great advantages of using a deep learning framework to build recommender models is the freedom to build rich, flexible feature representations.\n",
        "\n",
        "The first step in doing so is preparing the features, as raw features will usually not be immediately usable in a model.\n",
        "\n",
        "For example:\n",
        "\n",
        "- User and item ids may be strings (titles, usernames) or large, noncontiguous integers (database IDs).\n",
        "- Item descriptions could be raw text.\n",
        "- Interaction timestamps could be raw Unix timestamps.\n",
        "\n",
        "These need to be appropriately transformed in order to be useful in building models:\n",
        "\n",
        "- User and item ids have to be translated into embedding vectors: high-dimensional numerical representations that are adjusted during training to help the model predict its objective better.\n",
        "- Raw text needs to be tokenized (split into smaller parts such as individual words) and translated into embeddings.\n",
        "- Numerical features need to be normalized so that their values lie in a small interval around 0.\n",
        "\n",
        "Fortunately, by using TensorFlow we can make such preprocessing part of our model rather than a separate preprocessing step. This is not only convenient, but also ensures that our pre-processing is exactly the same during training and during serving. This makes it safe and easy to deploy models that include even very sophisticated pre-processing.\n",
        "\n",
        "In this tutorial, we are going to focus on recommenders and the preprocessing we need to do on the [MovieLens dataset](https://grouplens.org/datasets/movielens/). If you're interested in a larger tutorial without a recommender system focus, have a look at the full [Keras preprocessing guide](https://www.tensorflow.org/guide/keras/preprocessing_layers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh8vCHpi52gD"
      },
      "source": [
        "## The MovieLens dataset\n",
        "\n",
        "Let's first have a look at what features we can use from the MovieLens dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N3oCG2SE-dgf"
      },
      "outputs": [],
      "source": [
        "ratings_data = pd.read_csv(\"/content/mock-data_interaction.csv\", index_col = 0)\n",
        "recipes_data = pd.read_csv(\"/content/mock-data_recipe.csv\", index_col = 0).drop(columns = [\"nutritions\", \"image_url\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data.dateLastModified = pd.to_datetime(ratings_data.dateLastModified).astype(int)"
      ],
      "metadata": {
        "id": "ebXZbBMo8QFU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data.head() # TODO: parse inside the dataset or new csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Bl34y8cx-ODM",
        "outputId": "c044f585-42bf-4897-d4d0-5afab7f7e4db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    user_id  recipe_id  rating     dateLastModified\n",
              "0   8542392     222388       5  1492865203663000000\n",
              "1  11174581     222388       5  1371743425960000000\n",
              "2   8262477     222388       5  1423898871307000000\n",
              "3   3574785     240488       5  1507400408973000000\n",
              "4  12145410     240488       2  1515197169563000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e09df1d0-29e3-4aed-9256-7ed7774efbbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>recipe_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>dateLastModified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8542392</td>\n",
              "      <td>222388</td>\n",
              "      <td>5</td>\n",
              "      <td>1492865203663000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11174581</td>\n",
              "      <td>222388</td>\n",
              "      <td>5</td>\n",
              "      <td>1371743425960000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8262477</td>\n",
              "      <td>222388</td>\n",
              "      <td>5</td>\n",
              "      <td>1423898871307000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3574785</td>\n",
              "      <td>240488</td>\n",
              "      <td>5</td>\n",
              "      <td>1507400408973000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12145410</td>\n",
              "      <td>240488</td>\n",
              "      <td>2</td>\n",
              "      <td>1515197169563000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e09df1d0-29e3-4aed-9256-7ed7774efbbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e09df1d0-29e3-4aed-9256-7ed7774efbbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e09df1d0-29e3-4aed-9256-7ed7774efbbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7fe7fe3-059e-4821-b89a-eebcba45c5c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7fe7fe3-059e-4821-b89a-eebcba45c5c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7fe7fe3-059e-4821-b89a-eebcba45c5c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRqzuzoE9VRm",
        "outputId": "fb9ceb49-701b-4db0-95a2-ac89d2a869f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_id             int64\n",
              "recipe_id           int64\n",
              "rating              int64\n",
              "dateLastModified    int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings_data))\n",
        "recipes = tf.data.Dataset.from_tensor_slices(dict(recipes_data))"
      ],
      "metadata": {
        "id": "DJodSXrrukDs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BxQ_hy7xPH3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90edfdf-40ee-446d-d45a-47b15790a5e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'aver_rate': 5.0,\n",
            " 'cooking_directions': b\"{'directions': u'Prep\\\\n5 m\\\\nCook\\\\n2 h 45 m\\\\nRead\"\n",
            "                       b'y In\\\\n11 h 50 m\\\\nPreheat oven to 200 degrees F (95 d'\n",
            "                       b'egrees C).\\\\nSeason pork belly with paprika, salt, an'\n",
            "                       b'd pepper. Tightly wrap pork twice in heavy-duty alum'\n",
            "                       b'inum foil. Place on a baking sheet and bake in the p'\n",
            "                       b'reheated oven for 2 1/2 hours. Turn off the oven; le'\n",
            "                       b't pork rest in the oven for 1 hour. Remove meat from'\n",
            "                       b' oven, leaving it wrapped in aluminum foil, and refr'\n",
            "                       b'igerate at least 8 hours or overnight.\\\\nRemove pork '\n",
            "                       b'from foil and slice across the grain in 1/4-inch thi'\n",
            "                       b'ck slices. Working in batches, cook pork in a non-st'\n",
            "                       b'ick skillet over medium heat until golden and crispe'\n",
            "                       b\"d, 6 to 8 minutes per slice.'}\",\n",
            " 'ingredients': b'pork belly^smoked paprika^kosher salt^ground black pepper',\n",
            " 'recipe_id': 222388,\n",
            " 'recipe_name': b'Homemade Bacon',\n",
            " 'review_nums': 3,\n",
            " 'reviews': b\"{8542392: {'rating': 5, 'followersCount': 11, 'madeRecipesCount'\"\n",
            "            b\": 18, 'favoritesCount': 200, 'dateLastModified': u'2017-04-22T12\"\n",
            "            b':46:43.663\\', \\'text\\': u\"Best breakfast ever! I ran out of pap'\n",
            "            b'rika while seasoning, so I used garlic piercer on the other half'\n",
            "            b\" of the batch. Very good! Can't wait to make it again... and fig\"\n",
            "            b'ure out how to use the drippings!\", \\'followingCount\\': 0}, 11'\n",
            "            b\"174581: {'rating': 5, 'followersCount': 8, 'madeRecipesCount': 5\"\n",
            "            b\"5, 'favoritesCount': 101, 'dateLastModified': u'2013-06-20T15:50\"\n",
            "            b':25.96\\', \\'text\\': u\"Awesome!\\\\nIt\\'s amazing.\", \\'followingC'\n",
            "            b\"ount': 0}, 8262477: {'rating': 5, 'followersCount': 0, 'madeReci\"\n",
            "            b\"pesCount': 1, 'favoritesCount': 52, 'dateLastModified': u'2015-0\"\n",
            "            b\"2-14T07:27:51.307', 'text': u'The flavors came together well and\"\n",
            "            b' it really was simple to prepare. My husband and I both enjoyed '\n",
            "            b\"it!', 'followingCount': 0}}\\n\"}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "\n",
        "# for x in ratings.take(1).as_numpy_iterator():\n",
        "#   pprint.pprint(x)\n",
        "\n",
        "for x in recipes.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in recipes.take(3).as_numpy_iterator():\n",
        "  pprint.pprint(x[\"recipe_id\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzeJfE9Nx-9z",
        "outputId": "fd93800d-0db6-4931-d87c-39519ab5fcd1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "222388\n",
            "240488\n",
            "218939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGpAIhZ3xrnE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_recipe_ids = [222388, 240488, 218939]\n",
        "test_user_ids = [8542392, 174581, 8262477]"
      ],
      "metadata": {
        "id": "5xeExZpyxjIE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in ratings.take(1).as_numpy_iterator():\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYl6kujcu94i",
        "outputId": "72eee6ef-06c4-4ae1-bded-57400fe5d5a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'user_id': 8542392, 'recipe_id': 222388, 'rating': 5, 'dateLastModified': 1492865203663000000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ypp_nVub8J"
      },
      "source": [
        "There are a couple of key features here:\n",
        "\n",
        "- Movie title is useful as a movie identifier.\n",
        "- User id is useful as a user identifier.\n",
        "- Timestamps will allow us to model the effect of time.\n",
        "\n",
        "The first two are categorical features; timestamps are a continuous feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp2rd--gvW9w"
      },
      "source": [
        "## Turning categorical features into embeddings\n",
        "\n",
        "A [categorical feature](https://en.wikipedia.org/wiki/Categorical_variable) is a feature that does not express a continuous quantity, but rather takes on one of a set of fixed values.\n",
        "\n",
        "Most deep learning models express these feature by turning them into high-dimensional vectors. During model training, the value of that vector is adjusted to help the model predict its objective better.\n",
        "\n",
        "For example, suppose that our goal is to predict which user is going to watch which movie. To do that, we represent each user and each movie by an embedding vector. Initially, these embeddings will take on random values - but during training, we will adjust them so that embeddings of users and the movies they watch end up closer together.\n",
        "\n",
        "Taking raw categorical features and turning them into embeddings is normally a two-step process:\n",
        "\n",
        "1. Firstly, we need to translate the raw values into a range of contiguous integers, normally by building a mapping (called a \"vocabulary\") that maps raw values (\"Star Wars\") to integers (say, 15).\n",
        "2. Secondly, we need to take these integers and turn them into embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa-7so1D_9B2"
      },
      "source": [
        "### Defining the vocabulary\n",
        "\n",
        "The first step is to define a vocabulary. We can do this easily using Keras preprocessing layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IkA1HOXKyaEo"
      },
      "outputs": [],
      "source": [
        "# movie_title_lookup = tf.keras.layers.StringLookup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7We60Iduy2SP"
      },
      "source": [
        "The layer itself does not have a vocabulary yet, but we can build it using our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GKluOy3ly7Pg"
      },
      "outputs": [],
      "source": [
        "# movie_title_lookup.adapt(ratings.map(lambda x: x[\"movie_title\"]))\n",
        "\n",
        "# print(f\"Vocabulary: {movie_title_lookup.get_vocabulary()[:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cH2Je_KBQZy"
      },
      "source": [
        "Once we have this we can use the layer to translate raw tokens to embedding ids:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zXYpfmWDBVOq"
      },
      "outputs": [],
      "source": [
        "# movie_title_lookup([\"Star Wars (1977)\", \"One Flew Over the Cuckoo's Nest (1975)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYXiq04dzTaq"
      },
      "source": [
        "Note that the layer's vocabulary includes one (or more!) unknown (or \"out of vocabulary\", OOV) tokens. This is really handy: it means that the layer can handle categorical values that are not in the vocabulary. In practical terms, this means that the model can continue to learn about and make recommendations even using features that have not been seen during vocabulary construction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qseZxzmBBJvv"
      },
      "source": [
        "### Using feature hashing # Nope\n",
        "\n",
        "In fact, the `StringLookup` layer allows us to configure multiple OOV indices. If we do that, any raw value that is not in the vocabulary will be deterministically hashed to one of the OOV indices. The more such indices we have, the less likley it is that two different raw feature values will hash to the same OOV index. Consequently, if we have enough such indices the model should be able to train about as well as a model with an explicit vocabulary without the disdvantage of having to maintain the token list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0gOaMjJAC17"
      },
      "source": [
        "We can take this to its logical extreme and rely entirely on feature hashing, with no vocabulary at all. This is implemented in the `tf.keras.layers.Hashing` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1Os5gwGxzSaG"
      },
      "outputs": [],
      "source": [
        "# We set up a large number of bins to reduce the chance of hash collisions.\n",
        "num_hashing_bins = 10_000\n",
        "\n",
        "recipe_id_hashing = tf.keras.layers.Hashing(\n",
        "    num_bins=num_hashing_bins\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvcVNCzNB8GE"
      },
      "source": [
        "We can do the lookup as before without the need to build vocabularies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OkEWdeflCAY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b76ce43-60dc-4ba2-9755-6e3fcaa5c759"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([4076, 7649, 1185])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "recipe_id_hashing(test_recipe_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QFinPDA0LxM"
      },
      "source": [
        "### Defining the embeddings\n",
        "\n",
        "Now that we have integer ids, we can use the [`Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer to turn those into embeddings.\n",
        "\n",
        "An embedding layer has two dimensions: the first dimension tells us how many distinct categories we can embed; the second tells us how large the vector representing each of them can be.\n",
        "\n",
        "When creating the embedding layer for movie titles, we are going to set the first value to the size of our title vocabulary (or the number of hashing bins). The second is up to us: the larger it is, the higher the capacity of the model, but the slower it is to fit and serve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RUftFomv0nGO"
      },
      "outputs": [],
      "source": [
        "# movie_title_embedding = tf.keras.layers.Embedding(\n",
        "#     # Let's use the explicit vocabulary lookup.\n",
        "#     input_dim=movie_title_lookup.vocab_size(),\n",
        "#     output_dim=32\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_id_embedding = tf.keras.layers.Embedding(\n",
        "    # Let's use the explicit vocabulary lookup.\n",
        "    input_dim = recipe_id_hashing.num_bins,\n",
        "    output_dim=32\n",
        ")"
      ],
      "metadata": {
        "id": "pNvwsDVT0wF-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JNyTTQq1RIw"
      },
      "source": [
        "We can put the two together into a single layer which takes raw text in and yields embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RSbQd_mn1YYe"
      },
      "outputs": [],
      "source": [
        "recipe_id_model = tf.keras.Sequential([recipe_id_hashing, recipe_id_embedding])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QoA9YHw1gQc"
      },
      "source": [
        "Just like that, we can directly get the embeddings for our movie titles:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "T-s6uPqM1fZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72012134-7b31-40cb-e467-615f44d79555"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "recipe_id_model(test_recipe_ids).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2chJv4jTSg04"
      },
      "source": [
        "We can do the same with user embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3ot3bfX8SgWT"
      },
      "outputs": [],
      "source": [
        "user_id_lookup = tf.keras.layers.IntegerLookup()\n",
        "user_id_lookup.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
        "\n",
        "user_id_embedding = tf.keras.layers.Embedding(user_id_lookup.vocabulary_size(), 32)\n",
        "\n",
        "user_id_model = tf.keras.Sequential([user_id_lookup, user_id_embedding])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abZNsN3oDf1F"
      },
      "source": [
        "## Normalizing continuous features\n",
        "\n",
        "Continuous features also need normalization. For example, the `timestamp` feature is far too large to be used directly in a deep model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GGcKKOyLDsEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6da68a1-71da-4413-e5a2-b86ec9285cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 1492865203663000000.\n",
            "Timestamp: 1371743425960000000.\n",
            "Timestamp: 1423898871307000000.\n"
          ]
        }
      ],
      "source": [
        "for x in ratings.take(3).as_numpy_iterator(): # datetime in ns in original dataset\n",
        "  print(f\"Timestamp: {x['dateLastModified']}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aL_GMuaEBy0"
      },
      "source": [
        "We need to process it before we can use it. While there are many ways in which we can do this, discretization and standardization are two common ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCe-ch7eENNR"
      },
      "source": [
        "### Standardization\n",
        "\n",
        "[Standardization](https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)) rescales features to normalize their range by subtracting the feature's mean and dividing by its standard deviation. It is a common preprocessing transformation.\n",
        "\n",
        "This can be easily accomplished using the [`tf.keras.layers.Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) layer:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in ratings.take(3).as_numpy_iterator():\n",
        "  print((x[\"dateLastModified\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rlli7iT7cMD",
        "outputId": "86196d29-5b83-40ae-acd6-a886512eb9b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1492865203663000000\n",
            "1371743425960000000\n",
            "1423898871307000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WxPsx6iSLGrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2cc8bf3-a29a-40d7-94cb-3f705426c473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized timestamp: [1.3276442].\n",
            "Normalized timestamp: [0.42430067].\n",
            "Normalized timestamp: [0.8132836].\n"
          ]
        }
      ],
      "source": [
        "timestamp_normalization = tf.keras.layers.Normalization(\n",
        "    axis=None\n",
        ")\n",
        "timestamp_normalization.adapt(ratings.map(lambda x: x[\"dateLastModified\"]).batch(1024))\n",
        "\n",
        "for x in ratings.take(3).as_numpy_iterator():\n",
        "  print(f\"Normalized timestamp: {timestamp_normalization(x['dateLastModified'])}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_normalization([1492865203663000000, 1371743425960000000, 1423898871307000000])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I_GCbF0_JJO",
        "outputId": "ee901513-bb3f-42c9-b813-22d0d9eefcda"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.3276442 , 0.42430067, 0.8132836 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_normalization.mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwXCzPfUBbHe",
        "outputId": "b7cbbe59-e303-452d-dcbb-6cb6989ee025"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.3148525e+18], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_normalization.variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlEJHRG3_3Xl",
        "outputId": "9b12eaf7-1dae-4ef7-9dea-d0aefb175398"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.7977885e+34], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_normalization.invert = True\n",
        "\n",
        "print(timestamp_normalization([1.3276442 , 0.42430067, 0.8132836 ]))\n",
        "\n",
        "timestamp_normalization.invert = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuNEnlOZA0Ft",
        "outputId": "b16dd4e2-ab68-495a-d925-b02aac7d3d67"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1.4928652e+18 1.3717434e+18 1.4238989e+18], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW1B974ZPn71"
      },
      "source": [
        "### Discretization\n",
        "\n",
        "Another common transformation is to turn a continuous feature into a number of categorical features. This makes good sense if we have reasons to suspect that a feature's effect is non-continuous.\n",
        "\n",
        "To do this, we first need to establish the boundaries of the buckets we will use for discretization. The easiest way is to identify the minimum and maximum value of the feature, and divide the resulting interval equally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YlJK0rYyQGEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60c0287-d95a-49eb-9391-9d5319d18587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buckets: [1.00000000e+09 1.52170384e+15 3.04340669e+15]\n"
          ]
        }
      ],
      "source": [
        "max_timestamp = ratings.map(lambda x: x[\"dateLastModified\"]).reduce(\n",
        "    tf.cast(0, tf.int64), tf.maximum).numpy().max()\n",
        "min_timestamp = ratings.map(lambda x: x[\"dateLastModified\"]).reduce(\n",
        "    np.int64(1e9), tf.minimum).numpy().min()\n",
        "\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000)\n",
        "\n",
        "print(f\"Buckets: {timestamp_buckets[:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPS3fh5JQhkO"
      },
      "source": [
        "Given the bucket boundaries we can transform timestamps into embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VCizNzPkQmwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267e63bd-c4ff-4b0e-c696-71abe2cdd837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp embedding: [[ 0.01451284  0.04052303  0.03796265  0.0368779  -0.04211018  0.00981431\n",
            "  -0.01658794  0.03978509 -0.02062631 -0.02849709  0.03521403 -0.02704695\n",
            "   0.03403516  0.02407378  0.01432372 -0.0304164  -0.00678953  0.00885507\n",
            "  -0.04178615 -0.02547399 -0.03952188 -0.0204239   0.04537058  0.02627471\n",
            "   0.03975539 -0.01073929 -0.00779893  0.04215908 -0.02701466  0.02438667\n",
            "  -0.04121692 -0.01631363]].\n"
          ]
        }
      ],
      "source": [
        "timestamp_embedding_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "  tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32)\n",
        "])\n",
        "\n",
        "for timestamp in ratings.take(1).map(lambda x: x[\"dateLastModified\"]).batch(1).as_numpy_iterator():\n",
        "  print(f\"Timestamp embedding: {timestamp_embedding_model(timestamp)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWOg0NlGEeWh"
      },
      "source": [
        "## Processing text features\n",
        "\n",
        "We may also want to add text features to our model. Usually, things like product descriptions are free form text, and we can hope that our model can learn to use the information they contain to make better recommendations, especially in a cold-start or long tail scenario.\n",
        "\n",
        "While the MovieLens dataset does not give us rich textual features, we can still use movie titles. This may help us capture the fact that movies with very similar titles are likely to belong to the same series.\n",
        "\n",
        "The first transformation we need to apply to text is tokenization (splitting into constituent words or word-pieces), followed by vocabulary learning, followed by an embedding.\n",
        "\n",
        "The Keras [`tf.keras.layers.TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer can do the first two steps for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TdRa-_BXF7IJ"
      },
      "outputs": [],
      "source": [
        "title_text = tf.keras.layers.TextVectorization()\n",
        "title_text.adapt(recipes.map(lambda x: x[\"recipe_name\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJkYkgMQGxHL"
      },
      "source": [
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YAIj7TGOHAXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdff6480-73da-4353-edd0-a3ccd2ef369c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[174  25]], shape=(1, 2), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for row in recipes.batch(1).map(lambda x: x[\"recipe_name\"]).take(1):\n",
        "  print(title_text(row))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsQi_QGSH0it"
      },
      "source": [
        "Each title is translated into a sequence of tokens, one for each piece we've tokenized.\n",
        "\n",
        "We can check the learned vocabulary to verify that the layer is using the correct tokenization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "0gkJtiNyHzKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926be1a8-6496-4f24-fc52-cc41cff87409"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in', 'ii', 'goulash', 'garlic', 'frittata']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "title_text.get_vocabulary()[40:45]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_v-HFg0ICQS"
      },
      "source": [
        "This looks correct: the layer is tokenizing titles into individual words.\n",
        "\n",
        "To finish the processing, we now need to embed the text. Because each title contains multiple words, we will get multiple embeddings for each title. For use in a donwstream model these are usually compressed into a single embedding. Models like RNNs or Transformers are useful here, but averaging all the words' embeddings together is a good starting point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RomTZJ6N-z3Y"
      },
      "source": [
        "## Putting it all together\n",
        "\n",
        "With these components in place, we can build a model that does all the preprocessing together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMukupD2ggQh"
      },
      "source": [
        "### User model\n",
        "\n",
        "The full user model may look like the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TL_eYNyD-80t"
      },
      "outputs": [],
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "        user_id_lookup,\n",
        "        tf.keras.layers.Embedding(user_id_lookup.vocabulary_size(), 32),\n",
        "    ])\n",
        "    self.timestamp_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "      tf.keras.layers.Embedding(len(timestamp_buckets) + 2, 32)\n",
        "    ])\n",
        "    self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "        axis=None\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    # Take the input dictionary, pass it through each input layer,\n",
        "    # and concatenate the result.\n",
        "    return tf.concat([\n",
        "        self.user_embedding(inputs[\"user_id\"]),\n",
        "        self.timestamp_embedding(inputs[\"dateLastModified\"]),\n",
        "        tf.reshape(self.normalized_timestamp(inputs[\"dateLastModified\"]), (-1, 1))\n",
        "    ], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6brsz6mnDZV2"
      },
      "source": [
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LJlCFMgTDdC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06cb01af-0be6-49d5-ce95-e812249c7c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed representations: [ 0.02198341 -0.03796301  0.00759153]\n"
          ]
        }
      ],
      "source": [
        "user_model = UserModel()\n",
        "\n",
        "user_model.normalized_timestamp.adapt(\n",
        "    ratings.map(lambda x: x[\"dateLastModified\"]).batch(128))\n",
        "\n",
        "for row in ratings.batch(1).take(1):\n",
        "  print(f\"Computed representations: {user_model(row)[0, :3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_-_kmurEN4E"
      },
      "source": [
        "### Movie model\n",
        "We can do the same for the movie model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "n5k7fGmcETPl"
      },
      "outputs": [],
      "source": [
        "class RecipeModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.title_embedding = tf.keras.Sequential([\n",
        "      recipe_id_hashing,\n",
        "      tf.keras.layers.Embedding(recipe_id_hashing.num_bins, 32)\n",
        "    ])\n",
        "    self.title_text_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.TextVectorization(max_tokens=max_tokens),\n",
        "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
        "      # We average the embedding of individual words to get one embedding vector\n",
        "      # per title.\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.concat([\n",
        "        self.title_embedding(inputs[\"recipe_id\"]),\n",
        "        self.title_text_embedding(inputs[\"recipe_name\"]),\n",
        "    ], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzXelC5kJbsQ"
      },
      "source": [
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Tq3BWpzhJapY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3f309a-3946-4894-8fec-f97b18574141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed representation shape: (1, 64)\n"
          ]
        }
      ],
      "source": [
        "recipe_model = RecipeModel()\n",
        "\n",
        "recipe_model.title_text_embedding.layers[0].adapt(\n",
        "    recipes.map(lambda x: x[\"recipe_name\"]))\n",
        "\n",
        "for row in recipes.batch(1).take(1):\n",
        "  print(f\"Computed representation shape: {recipe_model(row).shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2dK71mPKoTw"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "With the two models above we've taken the first steps to representing rich features in a recommender model: to take this further and explore how these can be used to build an effective deep recomender model, take a look at our Deep Recommenders tutorial."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7tFtJt2Mloj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}