{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtuleva/Recipe_Recommendation_System/blob/main/tfrs_context_features_recreate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXZFq9EfewXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1VYK_CLfewIz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikhIvrku-i-L"
      },
      "source": [
        "# TFRS Recreate tutorial - Taking advantage of context features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrDVNe7Vdqhr"
      },
      "source": [
        "In [the featurization tutorial](featurization) we incorporated multiple features beyond just user and movie identifiers into our models, but we haven't explored whether those features improve model accuracy.\n",
        "\n",
        "Many factors affect whether features beyond ids are useful in a recommender model:\n",
        "\n",
        "1. __Importance of context__: if user preferences are relatively stable across contexts and time, context features may not provide much benefit. If, however, users preferences are highly contextual, adding context will improve the model significantly. For example, day of the week may be an important feature when deciding whether to recommend a short clip or a movie: users may only have time to watch short content during the week, but can relax and enjoy a full-length movie during the weekend. Similarly, query timestamps may play an important role in modelling popularity dynamics: one movie may be highly popular around the time of its release, but decay quickly afterwards. Conversely, other movies may be evergreens that are happily watched time and time again.\n",
        "2. __Data sparsity__: using non-id features may be critical if data is sparse. With few observations available for a given user or item, the model may struggle with estimating a good per-user or per-item representation. To build an accurate model, other features such as item categories, descriptions, and images have to be used to help the model generalize beyond the training data. This is especially relevant in [cold-start](https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)) situations, where relatively little data is available on some items or users.\n",
        "\n",
        "In this tutorial, we'll experiment with using features beyond movie titles and user ids to our MovieLens model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7RYXwgbAcbU"
      },
      "source": [
        "## Preliminaries\n",
        "\n",
        "We first import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2bK2g6_Mbn73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a082a3b8-c57a-441e-a094-b894f77eecaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/96.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/96.2 kB\u001b[0m \u001b[31m749.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m92.2/96.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-recommenders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmleYcLHAnkm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XbwMjnLP5nZ_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgKIjpQLAiax"
      },
      "source": [
        "We follow [the featurization tutorial](featurization) and keep the user id, timestamp, and movie title features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data = pd.read_csv(\"/content/mock-data_interaction.csv\", index_col = 0)\n",
        "recipes_data = pd.read_csv(\"/content/mock-data_recipe.csv\", index_col = 0).drop(columns = [\"nutritions\", \"image_url\"])\n",
        "\n",
        "ratings_data.dateLastModified = pd.to_datetime(ratings_data.dateLastModified).astype(int)\n",
        "\n"
      ],
      "metadata": {
        "id": "EDLLdU-je2uR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data = ratings_data.merge(\n",
        "    recipes_data[['recipe_id', 'recipe_name']],\n",
        "    on='recipe_id',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "y2c5JDSmmCbS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ESkhpwOMmbqB",
        "outputId": "bbcab888-9dbc-4ad4-ab30-5740b2b78de0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    user_id  recipe_id  rating     dateLastModified  \\\n",
              "0   8542392     222388       5  1492865203663000000   \n",
              "1  11174581     222388       5  1371743425960000000   \n",
              "2   8262477     222388       5  1423898871307000000   \n",
              "3   3574785     240488       5  1507400408973000000   \n",
              "4  12145410     240488       2  1515197169563000000   \n",
              "\n",
              "                         recipe_name  \n",
              "0                     Homemade Bacon  \n",
              "1                     Homemade Bacon  \n",
              "2                     Homemade Bacon  \n",
              "3  Pork Loin, Apples, and Sauerkraut  \n",
              "4  Pork Loin, Apples, and Sauerkraut  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b664c54-c671-4a7d-8f61-6d1b125fc716\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>recipe_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>dateLastModified</th>\n",
              "      <th>recipe_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8542392</td>\n",
              "      <td>222388</td>\n",
              "      <td>5</td>\n",
              "      <td>1492865203663000000</td>\n",
              "      <td>Homemade Bacon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11174581</td>\n",
              "      <td>222388</td>\n",
              "      <td>5</td>\n",
              "      <td>1371743425960000000</td>\n",
              "      <td>Homemade Bacon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8262477</td>\n",
              "      <td>222388</td>\n",
              "      <td>5</td>\n",
              "      <td>1423898871307000000</td>\n",
              "      <td>Homemade Bacon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3574785</td>\n",
              "      <td>240488</td>\n",
              "      <td>5</td>\n",
              "      <td>1507400408973000000</td>\n",
              "      <td>Pork Loin, Apples, and Sauerkraut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12145410</td>\n",
              "      <td>240488</td>\n",
              "      <td>2</td>\n",
              "      <td>1515197169563000000</td>\n",
              "      <td>Pork Loin, Apples, and Sauerkraut</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b664c54-c671-4a7d-8f61-6d1b125fc716')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b664c54-c671-4a7d-8f61-6d1b125fc716 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b664c54-c671-4a7d-8f61-6d1b125fc716');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38174bf7-5371-41c9-a3b2-bf1d4c0fd221\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38174bf7-5371-41c9-a3b2-bf1d4c0fd221')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38174bf7-5371-41c9-a3b2-bf1d4c0fd221 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings_data))\n",
        "recipes = tf.data.Dataset.from_tensor_slices(dict(recipes_data))"
      ],
      "metadata": {
        "id": "EbgQSrGEmMC7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kc2REbOO52Fl"
      },
      "outputs": [],
      "source": [
        "# ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "# movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
        "\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"recipe_id\": x[\"recipe_id\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"dateLastModified\": x[\"dateLastModified\"],\n",
        "    \"recipe_name\": x[\"recipe_name\"],\n",
        "\n",
        "})\n",
        "recipes = recipes.map(lambda x: {\n",
        "    \"recipe_id\": x[\"recipe_id\"],\n",
        "    \"recipe_name\": x[\"recipe_name\"],\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YZ2q5RXYNI6"
      },
      "source": [
        "We also do some housekeeping to prepare feature vocabularies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "G5CVveCS9Doq"
      },
      "outputs": [],
      "source": [
        "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"dateLastModified\"]).batch(100)))\n",
        "\n",
        "max_timestamp = timestamps.max()\n",
        "min_timestamp = timestamps.min()\n",
        "\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000,\n",
        ")\n",
        "\n",
        "unique_recipe_ids = np.unique(np.concatenate(list(recipes.batch(1000).map(\n",
        "    lambda x: x[\"recipe_id\"]\n",
        "))))\n",
        "\n",
        "unique_recipe_names = np.unique(np.concatenate(list(recipes.batch(1000).map(\n",
        "    lambda x: x[\"recipe_name\"]\n",
        "))))\n",
        "\n",
        "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
        "    lambda x: x[\"user_id\"]))))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFJcCVMUQou3"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtS6a4sgmI-c"
      },
      "source": [
        "### Query model\n",
        "\n",
        "We start with the user model defined in [the featurization tutorial](featurization) as the first layer of our model, tasked with converting raw input examples into feature embeddings. However, we change it slightly to allow us to turn timestamp features on or off. This will allow us to more easily demonstrate the effect that timestamp features have on the model. In the code below, the `use_timestamps` parameter gives us control over whether we use timestamp features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "_ItzYwMW42cb"
      },
      "outputs": [],
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, use_timestamps):\n",
        "    super().__init__()\n",
        "\n",
        "    self._use_timestamps = use_timestamps\n",
        "\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.IntegerLookup(\n",
        "            vocabulary=unique_user_ids, mask_token=None),\n",
        "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "    ])\n",
        "\n",
        "    if use_timestamps:\n",
        "      self.timestamp_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
        "      ])\n",
        "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "          axis=None\n",
        "      )\n",
        "\n",
        "      self.normalized_timestamp.adapt(timestamps)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if not self._use_timestamps:\n",
        "      return self.user_embedding(inputs[\"user_id\"])\n",
        "\n",
        "    return tf.concat([\n",
        "        self.user_embedding(inputs[\"user_id\"]),\n",
        "        self.timestamp_embedding(inputs[\"dateLastModified\"]),\n",
        "        tf.reshape(self.normalized_timestamp(inputs[\"dateLastModified\"]), (-1, 1)),\n",
        "    ], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9IqNTLmpJzs"
      },
      "source": [
        "Note that our use of timestamp features in this tutorial interacts with our choice of training-test split in an undesirable way. Because we have split our data randomly rather than chronologically (to ensure that events that belong to the test dataset happen later than those in the training set), our model can effectively learn from the future. This is unrealistic: after all, we cannot train a model today on data from tomorrow.\n",
        "\n",
        "This means that adding time features to the model lets it learn _future_ interaction patterns. We do this for illustration purposes only: the MovieLens dataset itself is very dense, and unlike many real-world datasets does not benefit greatly from features beyond user ids and movie titles.\n",
        "\n",
        "This caveat aside, real-world models may well benefit from other time-based features such as time of day or day of the week, especially if the data has strong seasonal patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XleMceZNHC__"
      },
      "source": [
        "### Candidate model\n",
        "\n",
        "For simplicity, we'll keep the candidate model fixed. Again, we copy it from the [featurization](featurization) tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "oQZHX8bEHPOk"
      },
      "outputs": [],
      "source": [
        "class RecipeModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.id_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.IntegerLookup(\n",
        "          vocabulary=unique_recipe_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_recipe_ids) + 1, 32)\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
        "        max_tokens=max_tokens)\n",
        "\n",
        "    self.title_text_embedding = tf.keras.Sequential([\n",
        "      self.title_vectorizer,\n",
        "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer.adapt(unique_recipe_names)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.concat([\n",
        "        self.id_embedding(inputs[\"recipe_id\"]),\n",
        "        self.title_text_embedding(inputs[\"recipe_name\"]),\n",
        "    ], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc4KbTNwHSvD"
      },
      "source": [
        "### Combined model\n",
        "\n",
        "With both `UserModel` and `MovieModel` defined, we can put together a combined model and implement our loss and metrics logic.\n",
        "\n",
        "Here we're building a retrieval model. For a refresher on how this works, see the [Basic retrieval](basic_retrieval.ipynb) tutorial.\n",
        "\n",
        "Note that we also need to make sure that the query model and candidate model output embeddings of compatible size. Because we'll be varying their sizes by adding more features, the easiest way to accomplish this is to use a dense projection layer after each model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "26_hNJPKIh4-"
      },
      "outputs": [],
      "source": [
        "class RecipeRecommedModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, use_timestamps):\n",
        "    super().__init__()\n",
        "    self.query_model = tf.keras.Sequential([\n",
        "      UserModel(use_timestamps),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.candidate_model = tf.keras.Sequential([\n",
        "      RecipeModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=recipes.batch(128).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings = self.query_model({\n",
        "        \"user_id\": features[\"user_id\"],\n",
        "        \"dateLastModified\": features[\"dateLastModified\"],\n",
        "    })\n",
        "    recipe_embeddings = self.candidate_model({\n",
        "        \"recipe_id\": features[\"recipe_id\"],\n",
        "        \"recipe_name\": features[\"recipe_name\"],\n",
        "    })\n",
        "\n",
        "    return self.task(query_embeddings, recipe_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YXjsRsLTVzt"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY7MTwMruoKh"
      },
      "source": [
        "### Prepare the data\n",
        "\n",
        "We first split the data into a training set and a testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "wMFUZ4dyTdYd"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(ratings.cardinality(), seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(6_000)\n",
        "test = shuffled.skip(6_000).take(2_000)\n",
        "\n",
        "cached_train = train.shuffle(6_000).batch(1024)\n",
        "cached_test = test.batch(512).cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2**9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd0k5qMqjx1b",
        "outputId": "1a66fe0c-6245-49d9-84c7-321f8028a2a1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2HEuTBzJ9w5"
      },
      "source": [
        "### Baseline: no timestamp features\n",
        "\n",
        "We're ready to try out our first model: let's start with not using timestamp features to establish our baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NkoLkiQdK4Um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4ecefd-7bc0-4270-cdcc-b94f136bd4d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "6/6 [==============================] - 3s 112ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0407 - factorized_top_k/top_5_categorical_accuracy: 0.1533 - factorized_top_k/top_10_categorical_accuracy: 0.2145 - factorized_top_k/top_50_categorical_accuracy: 0.4988 - factorized_top_k/top_100_categorical_accuracy: 0.9383 - loss: 6775.4819 - regularization_loss: 0.0000e+00 - total_loss: 6775.4819\n",
            "Epoch 2/3\n",
            "6/6 [==============================] - 1s 106ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1513 - factorized_top_k/top_5_categorical_accuracy: 0.3460 - factorized_top_k/top_10_categorical_accuracy: 0.4518 - factorized_top_k/top_50_categorical_accuracy: 0.7763 - factorized_top_k/top_100_categorical_accuracy: 0.9658 - loss: 6493.9994 - regularization_loss: 0.0000e+00 - total_loss: 6493.9994\n",
            "Epoch 3/3\n",
            "6/6 [==============================] - 1s 108ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2343 - factorized_top_k/top_5_categorical_accuracy: 0.6265 - factorized_top_k/top_10_categorical_accuracy: 0.7307 - factorized_top_k/top_50_categorical_accuracy: 0.9517 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 5691.8074 - regularization_loss: 0.0000e+00 - total_loss: 5691.8074\n",
            "6/6 [==============================] - 1s 101ms/step - factorized_top_k/top_1_categorical_accuracy: 0.4063 - factorized_top_k/top_5_categorical_accuracy: 0.7942 - factorized_top_k/top_10_categorical_accuracy: 0.8628 - factorized_top_k/top_50_categorical_accuracy: 0.9843 - factorized_top_k/top_100_categorical_accuracy: 0.9998 - loss: 4833.5418 - regularization_loss: 0.0000e+00 - total_loss: 4833.5418\n",
            "4/4 [==============================] - 1s 93ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0090 - factorized_top_k/top_5_categorical_accuracy: 0.0480 - factorized_top_k/top_10_categorical_accuracy: 0.0910 - factorized_top_k/top_50_categorical_accuracy: 0.4155 - factorized_top_k/top_100_categorical_accuracy: 0.9800 - loss: 3225.9107 - regularization_loss: 0.0000e+00 - total_loss: 3225.9107\n",
            "Top-100 accuracy (train): 1.00.\n",
            "Top-100 accuracy (test): 0.98.\n"
          ]
        }
      ],
      "source": [
        "model = RecipeRecommedModel(use_timestamps=False)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "model.fit(cached_train, epochs=3)\n",
        "\n",
        "train_accuracy = model.evaluate(\n",
        "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "test_accuracy = model.evaluate(\n",
        "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "\n",
        "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
        "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p90vFk8LvJXp"
      },
      "source": [
        "This gives us a baseline top-100 accuracy of around 0.2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjJ1anzuLXgN"
      },
      "source": [
        "### Capturing time dynamics with time features\n",
        "\n",
        "Do the result change if we add time features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "11qAr5gGMUxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5a60c9-c1a0-42ff-e9a7-df6c39372a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "6/6 [==============================] - 2s 110ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1173 - factorized_top_k/top_5_categorical_accuracy: 0.1593 - factorized_top_k/top_10_categorical_accuracy: 0.1890 - factorized_top_k/top_50_categorical_accuracy: 0.6253 - factorized_top_k/top_100_categorical_accuracy: 0.9567 - loss: 6928.2943 - regularization_loss: 0.0000e+00 - total_loss: 6928.2943\n",
            "Epoch 2/3\n",
            "6/6 [==============================] - 1s 112ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0807 - factorized_top_k/top_5_categorical_accuracy: 0.2418 - factorized_top_k/top_10_categorical_accuracy: 0.3657 - factorized_top_k/top_50_categorical_accuracy: 0.8810 - factorized_top_k/top_100_categorical_accuracy: 0.9983 - loss: 6254.6097 - regularization_loss: 0.0000e+00 - total_loss: 6254.6097\n",
            "Epoch 3/3\n",
            "6/6 [==============================] - 1s 112ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2133 - factorized_top_k/top_5_categorical_accuracy: 0.5580 - factorized_top_k/top_10_categorical_accuracy: 0.7287 - factorized_top_k/top_50_categorical_accuracy: 0.9882 - factorized_top_k/top_100_categorical_accuracy: 0.9998 - loss: 5293.4194 - regularization_loss: 0.0000e+00 - total_loss: 5293.4194\n",
            "6/6 [==============================] - 2s 107ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3827 - factorized_top_k/top_5_categorical_accuracy: 0.8418 - factorized_top_k/top_10_categorical_accuracy: 0.9330 - factorized_top_k/top_50_categorical_accuracy: 0.9982 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 4547.1648 - regularization_loss: 0.0000e+00 - total_loss: 4547.1648\n",
            "4/4 [==============================] - 0s 101ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0500 - factorized_top_k/top_5_categorical_accuracy: 0.1585 - factorized_top_k/top_10_categorical_accuracy: 0.2655 - factorized_top_k/top_50_categorical_accuracy: 0.7755 - factorized_top_k/top_100_categorical_accuracy: 0.9995 - loss: 3139.0164 - regularization_loss: 0.0000e+00 - total_loss: 3139.0164\n",
            "Top-100 accuracy (train): 1.00.\n",
            "Top-100 accuracy (test): 1.00.\n"
          ]
        }
      ],
      "source": [
        "model = RecipeRecommedModel(use_timestamps=True)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "model.fit(cached_train, epochs=3)\n",
        "\n",
        "train_accuracy = model.evaluate(\n",
        "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "test_accuracy = model.evaluate(\n",
        "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "\n",
        "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
        "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHnzYfQrOj8I"
      },
      "source": [
        "This is quite a bit better: not only is the training accuracy much higher, but the test accuracy is also substantially improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB09crfpgBx7"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "This tutorial shows that even simple models can become more accurate when incorporating more features. However, to get the most of your features it's often necessary to build larger, deeper models. Have a look at the [deep retrieval tutorial](deep_recommenders) to explore this in more detail."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}