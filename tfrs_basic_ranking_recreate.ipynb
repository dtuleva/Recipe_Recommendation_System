{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTJFqyrNGzz6P7JITHCFKL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtuleva/Recipe_Recommendation_System/blob/main/tfrd_basic_ranking_recreate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TkQ79hj0Tj43"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow --quiet"
      ],
      "metadata": {
        "id": "cUnhWx6wT6BJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pprint\n",
        "# import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "import mlflow"
      ],
      "metadata": {
        "id": "cG4lkvCpT9zW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recreate Recommending movies: ranking\n",
        "\n",
        "[tutorial link](https://www.tensorflow.org/recommenders/examples/basic_ranking)"
      ],
      "metadata": {
        "id": "mVe2d7vdTsr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataset\n",
        "\n",
        "We're going to use the same data as the [retrieval](basic_retrieval) tutorial. This time, we're also going to keep the ratings: these are the objectives we are trying to predict.\n",
        "\n",
        "As before, we'll split the data by putting 80% of the ratings in the train set, and 20% in the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "jkqWx9eqUyZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data = pd.read_csv(\"/content/mock-data_interaction.csv\", index_col = 0)\n",
        "# recipes_data = pd.read_csv(\"/content/mock-data_recipe.csv\")"
      ],
      "metadata": {
        "id": "d_IFZWLQP6-l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings_data))\n",
        "# recipes = tf.data.Dataset.from_tensor_slices(dict(recipes_data))"
      ],
      "metadata": {
        "id": "70F6IJEyR63G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rating in ratings.take(1):\n",
        "  for item in rating.items():\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWAwM17ZXmht",
        "outputId": "15c69101-8873-4c66-99ad-c8dc818c0bd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('user_id', <tf.Tensor: shape=(), dtype=int64, numpy=8542392>)\n",
            "('recipe_id', <tf.Tensor: shape=(), dtype=int64, numpy=222388>)\n",
            "('rating', <tf.Tensor: shape=(), dtype=int64, numpy=5>)\n",
            "('dateLastModified', <tf.Tensor: shape=(), dtype=string, numpy=b'2017-04-22T12:46:43.663\\n'>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature selection\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"recipe_id\": x[\"recipe_id\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"rating\": x[\"rating\"]\n",
        "})"
      ],
      "metadata": {
        "id": "owcigJDCSAK-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rating in ratings.take(1):\n",
        "  for item in rating.items():\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h94B7RndSEfI",
        "outputId": "0432e234-f7cc-48c6-f6cd-227ed3945bbf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('recipe_id', <tf.Tensor: shape=(), dtype=int64, numpy=222388>)\n",
            "('user_id', <tf.Tensor: shape=(), dtype=int64, numpy=8542392>)\n",
            "('rating', <tf.Tensor: shape=(), dtype=int64, numpy=5>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_recipe_id = 222388\n",
        "test_user_id = 8542392"
      ],
      "metadata": {
        "id": "vSSA1pWAVz2p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipes = ratings.map(lambda x: x[\"recipe_id\"])"
      ],
      "metadata": {
        "id": "sNp1F2_6aOtw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_cardinality = ratings.cardinality()\n",
        "ratings_cardinality"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5bymvjaSMoP",
        "outputId": "a96c9e1e-f38d-41bc-f659-51e245b8f1fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=8671>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(ratings.cardinality(), seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(6_000)\n",
        "test = shuffled.skip(6_000).take(2_000)"
      ],
      "metadata": {
        "id": "-WOJLiBqRyjo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also figure out unique user ids and movie titles present in the data.\n",
        "\n",
        "This is important because we need to be able to map the raw values of our categorical features to embedding vectors in our models. To do that, we need a vocabulary that maps a raw feature value to an integer in a contiguous range: this allows us to look up the corresponding embeddings in our embedding tables."
      ],
      "metadata": {
        "id": "NAdSYCL4VmRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_user_ids = ratings_data.user_id.unique()\n",
        "len(unique_user_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bisd1EeDUJw2",
        "outputId": "0b67247d-975b-42fc-92ca-a22687652050"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8266"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_recipe_ids = ratings_data.recipe_id.unique()\n",
        "len(unique_recipe_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBZ9TmEbVmpa",
        "outputId": "726d9184-cfca-4f6b-e3aa-726455ea4866"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_user_ids = np.unique(list(unique_user_ids))\n",
        "unique_recipe_ids = np.unique(list(unique_recipe_ids))"
      ],
      "metadata": {
        "id": "ZaZCjxelbo4d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a model"
      ],
      "metadata": {
        "id": "GBKhzq4cV8Or"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture\n",
        "\n",
        "Ranking models do not face the same efficiency constraints as retrieval models do, and so we have a little bit more freedom in our choice of architectures.\n",
        "\n",
        "A model composed of multiple stacked dense layers is a relatively common architecture for ranking tasks. We can implement it as follows:"
      ],
      "metadata": {
        "id": "V78mNKKFV9C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RankingModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    embedding_dimension = 32\n",
        "\n",
        "    # Compute embeddings for users.\n",
        "    self.user_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.IntegerLookup(\n",
        "        vocabulary=unique_user_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute embeddings for movies.\n",
        "    self.movie_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.IntegerLookup(\n",
        "        vocabulary=unique_recipe_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_recipe_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute predictions.\n",
        "    self.ratings = tf.keras.Sequential([\n",
        "      # Learn multiple dense layers.\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "      # Make rating predictions in the final layer.\n",
        "      tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    user_id, movie_title = inputs\n",
        "\n",
        "    user_embedding = self.user_embeddings(user_id)\n",
        "    movie_embedding = self.movie_embeddings(movie_title)\n",
        "\n",
        "    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
      ],
      "metadata": {
        "id": "N1aZY79dVnPO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model takes user ids and movie titles, and outputs a predicted rating:"
      ],
      "metadata": {
        "id": "kdDDCPs_ZiOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RankingModel()(([test_user_id], [test_recipe_id])) # not trained, just cheching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g1uvBQ9WF23",
        "outputId": "f674616c-0040-40e1-d009-43ee89f1df36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.01076964]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss and metrics\n",
        "\n",
        "The next component is the loss used to train our model. TFRS has several loss layers and tasks to make this easy.\n",
        "\n",
        "In this instance, we'll make use of the `Ranking` task object: a convenience wrapper that bundles together the loss function and metric computation.\n",
        "\n",
        "We'll use it together with the `MeanSquaredError` Keras loss in order to predict the ratings."
      ],
      "metadata": {
        "id": "ggxg7fpnaB-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = tfrs.tasks.Ranking(\n",
        "  loss = tf.keras.losses.MeanSquaredError(),\n",
        "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "id": "xcIHn65nZrMy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The task itself is a Keras layer that takes true and predicted as arguments, and returns the computed loss. We'll use that to implement the model's training loop."
      ],
      "metadata": {
        "id": "wHBo9UDVaX6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The full model\n",
        "\n",
        "We can now put it all together into a model. TFRS exposes a base model class (`tfrs.models.Model`) which streamlines bulding models: all we need to do is to set up the components in the `__init__` method, and implement the `compute_loss` method, taking in the raw features and returning a loss value.\n",
        "\n",
        "The base model will then take care of creating the appropriate training loop to fit our model."
      ],
      "metadata": {
        "id": "Vx2MfL-maidy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecipeRankingModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ranking_model: tf.keras.Model = RankingModel()\n",
        "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "      loss = tf.keras.losses.MeanSquaredError(),\n",
        "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    return self.ranking_model(\n",
        "        (features[\"user_id\"], features[\"recipe_id\"]))\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    labels = features.pop(\"rating\")\n",
        "\n",
        "    rating_predictions = self(features)\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(labels=labels, predictions=rating_predictions)"
      ],
      "metadata": {
        "id": "OzjhAeJdaVBn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting and evaluating\n",
        "\n",
        "After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model.\n",
        "\n",
        "Let's first instantiate the model."
      ],
      "metadata": {
        "id": "4pxOA-sAauf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RecipeRankingModel()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ],
      "metadata": {
        "id": "da12LPODavEO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then shuffle, batch, and cache the training and evaluation data."
      ],
      "metadata": {
        "id": "h1LQsuwIbQJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cached_train = train.shuffle(6000).batch(512).cache()\n",
        "cached_test = test.batch(2000).cache()"
      ],
      "metadata": {
        "id": "lf8JYs06bFLK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VglibtALfPno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then train the  model:"
      ],
      "metadata": {
        "id": "bL2CVuvvcAyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for el in cached_train.take(1):\n",
        "#   print(type(el))\n",
        "#   el.pop(\"rating\")\n",
        "#   print(el)"
      ],
      "metadata": {
        "id": "3-dWIZ1icOOg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = \"/content/log\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs)"
      ],
      "metadata": {
        "id": "GsaJKF59Oxad"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = mlflow.create_experiment(\"tfrs_basic_ranking_recreate_01\")"
      ],
      "metadata": {
        "id": "2Rm_IprSrsqn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.autolog()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8l2kF_Wpddx",
        "outputId": "61af1def-8ea6-4261-ab5f-7f0664b33ca0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/01/10 13:23:28 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lf8NMRE-gAPx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run(experiment_id = experiment, run_name=\"autolog_01\") as run:\n",
        "    model.fit(cached_train, epochs = 10, callbacks = [tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1koFuJdnYeWC",
        "outputId": "e275b467-9958-42b6-e64c-ed0a8e54857b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/01/10 13:23:30 WARNING mlflow.tensorflow: Encountered unexpected error while inferring batch size from training dataset: The layer \"recipe_ranking_model_1\" has never been called and thus has no defined input shape. Note that the `input_shape` property is only available for Functional and Sequential models.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "{'recipe_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>, 'rating': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
            "{'recipe_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>, 'rating': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
            "12/12 [==============================] - 1s 8ms/step - root_mean_squared_error: 2.7605 - loss: 6.9516 - regularization_loss: 0.0000e+00 - total_loss: 6.9516\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 8ms/step - root_mean_squared_error: 0.8126 - loss: 0.6606 - regularization_loss: 0.0000e+00 - total_loss: 0.6606\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 7ms/step - root_mean_squared_error: 0.7901 - loss: 0.6271 - regularization_loss: 0.0000e+00 - total_loss: 0.6271\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 8ms/step - root_mean_squared_error: 0.7852 - loss: 0.6196 - regularization_loss: 0.0000e+00 - total_loss: 0.6196\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 7ms/step - root_mean_squared_error: 0.7811 - loss: 0.6128 - regularization_loss: 0.0000e+00 - total_loss: 0.6128\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 7ms/step - root_mean_squared_error: 0.7764 - loss: 0.6051 - regularization_loss: 0.0000e+00 - total_loss: 0.6051\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 7ms/step - root_mean_squared_error: 0.7703 - loss: 0.5951 - regularization_loss: 0.0000e+00 - total_loss: 0.5951\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 7ms/step - root_mean_squared_error: 0.7620 - loss: 0.5816 - regularization_loss: 0.0000e+00 - total_loss: 0.5816\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 8ms/step - root_mean_squared_error: 0.7504 - loss: 0.5630 - regularization_loss: 0.0000e+00 - total_loss: 0.5630\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 7ms/step - root_mean_squared_error: 0.7340 - loss: 0.5369 - regularization_loss: 0.0000e+00 - total_loss: 0.5369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/01/10 13:23:33 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'tensorflow.python.data.ops.cache_op.CacheDataset'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
            "2024/01/10 13:23:33 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "2024/01/10 13:23:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the model trains, the loss is falling and the RMSE metric is improving."
      ],
      "metadata": {
        "id": "ke5P1XeOjH-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can evaluate our model on the test set:"
      ],
      "metadata": {
        "id": "_mB7BUIujOB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(cached_test, return_dict = True, callbacks = [tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivGen_0jb8qz",
        "outputId": "43d0a052-3808-465a-c398-909faca6df00"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'recipe_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>, 'rating': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
            "1/1 [==============================] - 0s 446ms/step - root_mean_squared_error: 0.8285 - loss: 0.6864 - regularization_loss: 0.0000e+00 - total_loss: 0.6864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'root_mean_squared_error': 0.8284972310066223,\n",
              " 'loss': 0.6864076852798462,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 0.6864076852798462}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lower the RMSE metric, the more accurate our model is at predicting ratings."
      ],
      "metadata": {
        "id": "1hAZMPMkjeYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the ranking model\n",
        "\n",
        "Now we can test the ranking model by computing predictions for a set of movies and then rank these movies based on the predictions:"
      ],
      "metadata": {
        "id": "4i4D2W7vjhwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratings = {}\n",
        "test_movie_titles = [test_recipe_id]\n",
        "for movie_title in test_movie_titles:\n",
        "  test_ratings[movie_title] = model({\n",
        "      \"user_id\": np.array([test_recipe_id]),\n",
        "      \"recipe_id\": np.array([movie_title])\n",
        "  })\n",
        "\n",
        "print(\"Ratings:\")\n",
        "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "  print(f\"{title}: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3ui-Tnyb_2K",
        "outputId": "e311e3bd-fc6e-41fd-bd74-5ac72844e612"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings:\n",
            "222388: [[4.348587]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# real rating 5; TODO: add more test pairs"
      ],
      "metadata": {
        "id": "8lF0g93jkJf0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting for serving\n",
        "\n",
        "The model can be easily exported for serving:\n"
      ],
      "metadata": {
        "id": "1a9gHpc3kXbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, \"tfrs_basic_ranking_model\")"
      ],
      "metadata": {
        "id": "GYZHQKScjxgI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now load it back and perform predictions:"
      ],
      "metadata": {
        "id": "lGgqIa41kgAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = tf.saved_model.load(\"/content/tfrs_basic_ranking_model\")\n",
        "\n",
        "loaded({\"user_id\": np.array([test_user_id]), \"recipe_id\": [test_recipe_id]}).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0U5PjnSksgs",
        "outputId": "cbabeb05-829c-483e-bf2d-97be3dab6796"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3248014]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the model to TensorFLow Lite\n",
        "\n",
        "nope"
      ],
      "metadata": {
        "id": "hkBnKrAslQtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "The model above gives us a decent start towards building a ranking system.\n",
        "\n",
        "Of course, making a practical ranking system requires much more effort.\n",
        "\n",
        "In most cases, a ranking model can be substantially improved by using more features rather than just user and candidate identifiers. To see how to do that, have a look at the [side features](featurization) tutorial.\n",
        "\n",
        "A careful understanding of the objectives worth optimizing is also necessary. To get started on building a recommender that optimizes multiple objectives, have a look at our [multitask](multitask) tutorial."
      ],
      "metadata": {
        "id": "eiUNTZPtlYtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zip saved model, tensorboard and mlflow runs for downloading from colab"
      ],
      "metadata": {
        "id": "fqUDEKhklaVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        "\n",
        "# %reload_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir=\"/content/log\""
      ],
      "metadata": {
        "id": "-R_GwIIDlLKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip mlflow logs\n",
        "!zip -r /content/mlflow_basic_ranking.zip /content/mlruns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccV5iAIyl2Ba",
        "outputId": "7374e0c9-6e2c-4030-a88b-c75b07ac3158"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/mlruns/ (stored 0%)\n",
            "  adding: content/mlruns/0/ (stored 0%)\n",
            "  adding: content/mlruns/0/datasets/ (stored 0%)\n",
            "  adding: content/mlruns/0/datasets/eb231e126f93da5e54765425072f5747/ (stored 0%)\n",
            "  adding: content/mlruns/0/datasets/eb231e126f93da5e54765425072f5747/meta.yaml (deflated 53%)\n",
            "  adding: content/mlruns/0/datasets/74ea8d26a002b2df1f7bda269c6014c4/ (stored 0%)\n",
            "  adding: content/mlruns/0/datasets/74ea8d26a002b2df1f7bda269c6014c4/meta.yaml (deflated 52%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/ (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/tags/ (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/tags/mlflow.autologging (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/meta.yaml (deflated 45%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/ (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/workers (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/inputs/7bec167f8e5ffb805de7bd909155c575/ (stored 0%)\n",
            "  adding: content/mlruns/0/f8d093dd2ea1433082acc13792e79464/inputs/7bec167f8e5ffb805de7bd909155c575/meta.yaml (deflated 31%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/ (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/tags/ (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/tags/mlflow.autologging (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/meta.yaml (deflated 45%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/ (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/workers (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/inputs/4b42afbd9c35b24f71e832858c19716c/ (stored 0%)\n",
            "  adding: content/mlruns/0/a97d8c069644435492d5173acca88270/inputs/4b42afbd9c35b24f71e832858c19716c/meta.yaml (deflated 30%)\n",
            "  adding: content/mlruns/0/meta.yaml (deflated 24%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/ (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/tags/ (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/tags/mlflow.autologging (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/meta.yaml (deflated 45%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/ (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/workers (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/inputs/e90449e8512a6d31da4d2a2b3d3d0d7e/ (stored 0%)\n",
            "  adding: content/mlruns/0/e5a75b6ebf624b3995bb421adaff48ef/inputs/e90449e8512a6d31da4d2a2b3d3d0d7e/meta.yaml (deflated 31%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/ (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/tags/ (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/tags/mlflow.autologging (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/meta.yaml (deflated 44%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/ (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/workers (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/inputs/55931dfcaf4b5293cdd9d5b5ab3e6754/ (stored 0%)\n",
            "  adding: content/mlruns/0/e1714d7fb4434d65810b49471fae5a75/inputs/55931dfcaf4b5293cdd9d5b5ab3e6754/meta.yaml (deflated 30%)\n",
            "  adding: content/mlruns/.trash/ (stored 0%)\n",
            "  adding: content/mlruns/388711542430781400/ (stored 0%)\n",
            "  adding: content/mlruns/388711542430781400/meta.yaml (deflated 32%)\n",
            "  adding: content/mlruns/278107012914904571/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/datasets/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/datasets/5ee1879c83f2d36a834ad98a4f9979f3/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/datasets/5ee1879c83f2d36a834ad98a4f9979f3/meta.yaml (deflated 52%)\n",
            "  adding: content/mlruns/278107012914904571/datasets/eb231e126f93da5e54765425072f5747/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/datasets/eb231e126f93da5e54765425072f5747/meta.yaml (deflated 53%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/tags/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/meta.yaml (deflated 46%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/workers (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/inputs/6a7d551200ad20f9e36ae69ff314c363/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/f639a6b7ca344851bf69affd641a44ac/inputs/6a7d551200ad20f9e36ae69ff314c363/meta.yaml (deflated 30%)\n",
            "  adding: content/mlruns/278107012914904571/meta.yaml (deflated 32%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/metrics/regularization_loss (deflated 60%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/metrics/total_loss (deflated 55%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/metrics/loss (deflated 55%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/metrics/root_mean_squared_error (deflated 55%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/tags/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/tags/mlflow.log-model.history (deflated 42%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704893010.c4d4cdb7b2eb.15866.1.v2 (deflated 88%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704892392.c4d4cdb7b2eb.239.3.v2 (deflated 8%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704892305.c4d4cdb7b2eb.239.2.v2 (deflated 5%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704891361.c4d4cdb7b2eb.239.0.v2 (deflated 5%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704892431.c4d4cdb7b2eb.239.5.v2 (deflated 5%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704892512.c4d4cdb7b2eb.13851.0.v2 (deflated 6%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704892961.c4d4cdb7b2eb.15866.0.v2 (deflated 5%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704892430.c4d4cdb7b2eb.239.4.v2 (deflated 5%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/tensorboard_logs/train/events.out.tfevents.1704892196.c4d4cdb7b2eb.239.1.v2 (deflated 6%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/global_custom_objects.cloudpickle (deflated 61%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/save_format.txt (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/keras_module.txt (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/model/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/model/fingerprint.pb (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/model/keras_metadata.pb (deflated 64%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/model/assets/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/model/variables/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/model/variables/variables.data-00000-of-00001 (deflated 33%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/model/variables/variables.index (deflated 56%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/data/model/saved_model.pb (deflated 81%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/requirements.txt (deflated 17%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/python_env.yaml (deflated 18%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/MLmodel (deflated 41%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/artifacts/model/conda.yaml (deflated 31%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/meta.yaml (deflated 46%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/workers (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/inputs/03a559b7d01e158b939cf06d8cff67ec/ (stored 0%)\n",
            "  adding: content/mlruns/278107012914904571/3125d384d4d74777b92bf3bc2bfbb512/inputs/03a559b7d01e158b939cf06d8cff67ec/meta.yaml (deflated 31%)\n",
            "  adding: content/mlruns/159978474677509058/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/tags/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/meta.yaml (deflated 46%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/workers (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/inputs/a01c9c354f067f444bf784100c0a01ef/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/51069c66e2c84a999c6f5abbe8334b91/inputs/a01c9c354f067f444bf784100c0a01ef/meta.yaml (deflated 30%)\n",
            "  adding: content/mlruns/159978474677509058/datasets/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/datasets/eb231e126f93da5e54765425072f5747/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/datasets/eb231e126f93da5e54765425072f5747/meta.yaml (deflated 53%)\n",
            "  adding: content/mlruns/159978474677509058/datasets/74ea8d26a002b2df1f7bda269c6014c4/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/datasets/74ea8d26a002b2df1f7bda269c6014c4/meta.yaml (deflated 52%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/tags/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/meta.yaml (deflated 46%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/workers (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/inputs/4d3b2d5549ff49c269968f6340a6bfd2/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/1f852deeaf594133aba7d9e45e9a8f0d/inputs/4d3b2d5549ff49c269968f6340a6bfd2/meta.yaml (deflated 31%)\n",
            "  adding: content/mlruns/159978474677509058/meta.yaml (deflated 32%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/metrics/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/tags/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/tags/mlflow.user (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/tags/mlflow.source.name (deflated 5%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/tags/mlflow.runName (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/tags/mlflow.source.type (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/meta.yaml (deflated 46%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_jit_compile (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_epsilon (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/max_queue_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/validation_freq (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_learning_rate (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/validation_steps (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_name (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_weight_decay (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_global_clipnorm (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/validation_batch_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/validation_split (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/workers (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/class_weight (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/shuffle (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_initial_accumulator_value (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_clipvalue (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/initial_epoch (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_ema_overwrite_frequency (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_is_legacy_optimizer (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/batch_size (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/steps_per_epoch (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/sample_weight (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/epochs (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_ema_momentum (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/use_multiprocessing (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/params/opt_use_ema (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/inputs/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/inputs/9eff53d00cabc9de8c6237896fc0b46a/ (stored 0%)\n",
            "  adding: content/mlruns/159978474677509058/3f244286c85a4240a359439dc9fee47b/inputs/9eff53d00cabc9de8c6237896fc0b46a/meta.yaml (deflated 30%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip model\n",
        "!zip -r /content/tfrs_basic_ranking_model /content/tfrs_basic_ranking_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI9PQN8FmGxs",
        "outputId": "0d5bc70a-a93a-47b0-89a7-47ecbc8bee04"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/tfrs_basic_ranking_model/ (stored 0%)\n",
            "  adding: content/tfrs_basic_ranking_model/fingerprint.pb (stored 0%)\n",
            "  adding: content/tfrs_basic_ranking_model/assets/ (stored 0%)\n",
            "  adding: content/tfrs_basic_ranking_model/variables/ (stored 0%)\n",
            "  adding: content/tfrs_basic_ranking_model/variables/variables.data-00000-of-00001 (deflated 33%)\n",
            "  adding: content/tfrs_basic_ranking_model/variables/variables.index (deflated 56%)\n",
            "  adding: content/tfrs_basic_ranking_model/saved_model.pb (deflated 81%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip tensorboard logs\n",
        "!zip -r /content/log.zip /content/log/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-6gS8ywmeRA",
        "outputId": "4427984e-27be-43e4-bdd1-be83ae99c06d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/log/ (stored 0%)\n",
            "  adding: content/log/validation/ (stored 0%)\n",
            "  adding: content/log/validation/events.out.tfevents.1704893179.c4d4cdb7b2eb.15866.3.v2 (deflated 41%)\n",
            "  adding: content/log/train/ (stored 0%)\n",
            "  adding: content/log/train/events.out.tfevents.1704893010.c4d4cdb7b2eb.15866.1.v2 (deflated 88%)\n",
            "  adding: content/log/train/events.out.tfevents.1704892392.c4d4cdb7b2eb.239.3.v2 (deflated 8%)\n",
            "  adding: content/log/train/events.out.tfevents.1704892305.c4d4cdb7b2eb.239.2.v2 (deflated 5%)\n",
            "  adding: content/log/train/events.out.tfevents.1704891361.c4d4cdb7b2eb.239.0.v2 (deflated 5%)\n",
            "  adding: content/log/train/events.out.tfevents.1704893179.c4d4cdb7b2eb.15866.2.v2 (deflated 5%)\n",
            "  adding: content/log/train/events.out.tfevents.1704892431.c4d4cdb7b2eb.239.5.v2 (deflated 5%)\n",
            "  adding: content/log/train/events.out.tfevents.1704892512.c4d4cdb7b2eb.13851.0.v2 (deflated 6%)\n",
            "  adding: content/log/train/events.out.tfevents.1704892961.c4d4cdb7b2eb.15866.0.v2 (deflated 5%)\n",
            "  adding: content/log/train/events.out.tfevents.1704892430.c4d4cdb7b2eb.239.4.v2 (deflated 5%)\n",
            "  adding: content/log/train/events.out.tfevents.1704892196.c4d4cdb7b2eb.239.1.v2 (deflated 6%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pk5JhVsnmkN8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}